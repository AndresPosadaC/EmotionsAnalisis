{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install FER\n",
    "\n",
    "from fer import Video\n",
    "from fer import FER\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put in the location of the video file that has to be processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_videofile = \"Mayorquin01.mov\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Face detection detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detector = FER(mtcnn=True)\n",
    "input_video = Video(location_videofile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Analyze() function will run analysis on every frame of the input video. It will create a rectangular box around every image and show the emotion values next to that. Finally, the method will publish a new video that will have a box around the face of the human with live emotion values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_data = input_video.analyze(face_detector, display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the analysed information into a dataframe. This will help us import the data as a .CSV file to perform analysis over it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_df = input_video.to_pandas(processing_data)\n",
    "vid_df = input_video.get_first_face(vid_df)\n",
    "vid_df = input_video.get_emotions(vid_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the emotions against time in the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pltfig = vid_df.plot(figsize=(30, 6), fontsize=12).get_figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe to extract which emotion was prominent in the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angry = sum(vid_df.angry)\n",
    "disgust = sum(vid_df.disgust)\n",
    "fear = sum(vid_df.fear)\n",
    "happy = sum(vid_df.happy)\n",
    "sad = sum(vid_df.sad)\n",
    "surprise = sum(vid_df.surprise)\n",
    "neutral = sum(vid_df.neutral)\n",
    "\n",
    "emotions = ['Enojo', 'Desagrado', 'Miedo', 'Alegria', 'Tristeza', 'Sorpresa', 'Neutro']\n",
    "emotions_values = [angry, disgust, fear, happy, sad, surprise, neutral]\n",
    "\n",
    "score_comparisons = pd.DataFrame(emotions, columns = ['Emaciones Humanas'])\n",
    "score_comparisons['Valor Emocional en Video'] = emotions_values\n",
    "score_comparisons"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
